{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT-fy CORD-19 data\n",
    "\n",
    "Original code from https://www.kaggle.com/theamrzaki/covid-19-bert-researchpapers-semantic-search#Data-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_size = 'full'\n",
    "all_data_path = './../data/'\n",
    "data_path = f'./../data/{dataset_size}/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_json = glob.glob(f'{all_data_path}/**/*.json', recursive=True)\n",
    "\n",
    "len(all_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# get only rows with attached files\n",
    "\n",
    "metadata_path = f'{all_data_path}/metadata.csv'\n",
    "stripped_metadata_path = f'{all_data_path}/stripped_metadata.csv'\n",
    "\n",
    "if not os.path.exists(stripped_metadata_path):\n",
    "    meta_df = pd.read_csv(metadata_path, dtype={\n",
    "        'pubmed_id': str,\n",
    "        'Microsoft Academic Paper ID': str,\n",
    "        'doi': str\n",
    "    })\n",
    "\n",
    "    stripped_meta_df = meta_df.dropna(subset=['pmc_json_files'])\n",
    "\n",
    "    stripped_meta_df.to_csv(stripped_metadata_path)\n",
    "\n",
    "    stripped_meta_df.head()\n",
    "\n",
    "    del stripped_meta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# create shuffled subset of metadata rows\n",
    "\n",
    "small_metadata_path = f'{all_data_path}/small/metadata.csv'\n",
    "if not os.path.exists(small_metadata_path):\n",
    "    small_metadata_file = open(f'{all_data_path}/small/metadata.csv', 'w')\n",
    "    # get header from metadata.csv\n",
    "    print(subprocess.run(\n",
    "        ['head', '-n 1', f'{all_data_path}/stripped_metadata.csv'], stdout=small_metadata_file))\n",
    "    #!head -n 1 \"{all_data_path}/stripped_metadata.csv\" > \"{all_data_path}/metadata.csv\"\n",
    "    # get random sample from metadata.csv\n",
    "    print(subprocess.run(\n",
    "        ['shuf', '-n 12500', f'{all_data_path}/stripped_metadata.csv'], stdout=small_metadata_file))\n",
    "    #!shuf -n 12500 \"{all_data_path}/stripped_metadata.csv\" >> \"{root_path}/metadata.csv\"\n",
    "    small_metadata_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# create shuffled subset of metadata rows\n",
    "\n",
    "full_metadata_path = f'{all_data_path}/full/metadata.csv'\n",
    "if not os.path.exists(full_metadata_path):\n",
    "    full_metadata_file = open(f'{all_data_path}/full/metadata.csv', 'w')\n",
    "    print(subprocess.run(\n",
    "        ['cat', f'{all_data_path}/stripped_metadata.csv'], stdout=full_metadata_file))\n",
    "    full_metadata_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = f'{data_path}/metadata.csv'\n",
    "\n",
    "meta_df = pd.read_csv(metadata_path, dtype={\n",
    "    'pubmed_id': str,\n",
    "    'Microsoft Academic Paper ID': str,\n",
    "    'doi': str\n",
    "})\n",
    "\n",
    "meta_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "class Article:\n",
    "    def __init__(self, pmcid):\n",
    "\n",
    "        self.paper_id = ''\n",
    "        self.abstract = []\n",
    "        self.body_text = []\n",
    "\n",
    "\n",
    "        if not isinstance(pmcid, str) and math.isnan(pmcid):\n",
    "            return\n",
    "\n",
    "        with open(f\"{all_data_path}/document_parses/pmc_json/{pmcid}.xml.json\") as file:\n",
    "            content = json.load(file)\n",
    "            content_metadata = meta_df.loc[meta_df['pmcid'] == pmcid]\n",
    "\n",
    "            self.paper_id = content['paper_id']\n",
    "            self.abstract = []\n",
    "            self.body_text = []\n",
    "            self.metadata = {}\n",
    "\n",
    "            if not content_metadata is None:\n",
    "                self.metadata = content_metadata\n",
    "\n",
    "            if 'abstract' in content_metadata:\n",
    "                # Abstract\n",
    "                # self.abstract.append(content_metadata['abstract'][0])\n",
    "                for entry in content_metadata['abstract']:\n",
    "                    self.abstract.append(str(entry))\n",
    "                # print(self.abstract)\n",
    "            # Body text\n",
    "            if 'body_text' in content:\n",
    "                for entry in content['body_text']:\n",
    "                    self.body_text.append(entry['text'])\n",
    "\n",
    "            self.abstract = '<br>'.join(self.abstract)\n",
    "            self.body_text = '<br>'.join(self.body_text)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.paper_id}: {self.abstract[:200]}... {self.body_text[:200]}...'\n",
    "\n",
    "\n",
    "first_row = Article(meta_df['pmcid'][0])\n",
    "print(first_row.body_text)\n",
    "# meta_df.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "\n",
    "global partial_df\n",
    "global dict_\n",
    "\n",
    "dict_ = {'paper_id': [], 'abstract': [], 'body_text': []}\n",
    "partial_df = pd.DataFrame(dict_, columns=[\n",
    "    'paper_id', 'abstract', 'body_text'])\n",
    "partial_df = dd.from_pandas(partial_df, npartitions=10)\n",
    "\n",
    "partial_df.compute().to_csv(f'{data_path}/df_covid.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def populateDict(content):\n",
    "    # no metadata, skip this paper\n",
    "    if len(content.metadata) == 0:\n",
    "        return\n",
    "\n",
    "    # print(meta_data)\n",
    "\n",
    "    dict_['paper_id'].append(content.paper_id)\n",
    "    dict_['abstract'].append(content.abstract.replace('\\n', '<br>'))\n",
    "    dict_['body_text'].append(content.body_text.replace('\\n', '<br>'))\n",
    "\n",
    "\n",
    "def saveProgress():\n",
    "    global partial_df\n",
    "    global dict_\n",
    "\n",
    "    partial_df = pd.DataFrame(dict_, columns=[\n",
    "        'paper_id', 'abstract', 'body_text'])\n",
    "    partial_df = dd.from_pandas(partial_df, npartitions=1)\n",
    "\n",
    "    print('saving current progress')\n",
    "    partial_df.compute().to_csv(\n",
    "        f'{data_path}/df_covid.csv', mode='a', header=False, index=False)\n",
    "\n",
    "    print('reseting partial df')\n",
    "    del partial_df\n",
    "\n",
    "    print('reseting partial dict')\n",
    "    del dict_\n",
    "    dict_ = {'paper_id': [], 'abstract': [], 'body_text': []}\n",
    "\n",
    "\n",
    "for idx, entry in enumerate(meta_df['pmcid']):\n",
    "    if idx % 1000 == 0:\n",
    "        print(f'Processing index: {idx} of {len(meta_df)}')\n",
    "        saveProgress()\n",
    "\n",
    "    populateDict(Article(entry))\n",
    "\n",
    "saveProgress()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import dataframe as dd\n",
    "import re\n",
    "\n",
    "\n",
    "def lower_case(input_str):\n",
    "    input_str = input_str.lower()\n",
    "    return input_str\n",
    "\n",
    "\n",
    "df_covid = dd.read_csv(f'{data_path}/df_covid.csv')\n",
    "\n",
    "df_covid['body_text'] = df_covid['body_text'].astype(str)\n",
    "df_covid['abstract'] = df_covid['abstract'].astype(str)\n",
    "\n",
    "df_covid['abstract'] = df_covid['abstract'].apply(\n",
    "    lambda x: re.sub('[^a-zA-z0-9\\s]', '', x), meta=('abstract', 'str'))\n",
    "df_covid['body_text'] = df_covid['body_text'].apply(\n",
    "    lambda x: re.sub('[^a-zA-z0-9\\s]', '', x), meta=('body_text', 'str'))\n",
    "\n",
    "df_covid['abstract'] = df_covid['abstract'].apply(\n",
    "    lambda x: lower_case(x), meta=('abstract', 'str'))\n",
    "df_covid['body_text'] = df_covid['body_text'].apply(\n",
    "    lambda x: lower_case(x), meta=('body_text', 'str'))\n",
    "\n",
    "df_covid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_covid.to_csv(f'{data_path}/df_covid_preprocessed.csv', single_file=True, compute=True, index=False)\n",
    "\n",
    "df_covid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>body_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC35282</td>\n",
       "      <td>objective this retrospective chart review desc...</td>\n",
       "      <td>mycoplasma pneumoniae is a common cause of upp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC59543</td>\n",
       "      <td>inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>since its discovery as a biological messenger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC59549</td>\n",
       "      <td>surfactant proteind spd participates in the in...</td>\n",
       "      <td>surfactant proteind spd is a member of the col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC59574</td>\n",
       "      <td>endothelin1 et1 is a 21 amino acid peptide wit...</td>\n",
       "      <td>et1 et2 and et3 are members of a peptide famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC59580</td>\n",
       "      <td>respiratory syncytial virus rsv and pneumonia ...</td>\n",
       "      <td>rsv and pvm are viruses of the family paramyxo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                           abstract  \\\n",
       "0  PMC35282  objective this retrospective chart review desc...   \n",
       "1  PMC59543  inflammatory diseases of the respiratory tract...   \n",
       "2  PMC59549  surfactant proteind spd participates in the in...   \n",
       "3  PMC59574  endothelin1 et1 is a 21 amino acid peptide wit...   \n",
       "4  PMC59580  respiratory syncytial virus rsv and pneumonia ...   \n",
       "\n",
       "                                           body_text  \n",
       "0  mycoplasma pneumoniae is a common cause of upp...  \n",
       "1  since its discovery as a biological messenger ...  \n",
       "2  surfactant proteind spd is a member of the col...  \n",
       "3  et1 et2 and et3 are members of a peptide famil...  \n",
       "4  rsv and pvm are viruses of the family paramyxo...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "df_covid = dd.read_csv(f'{data_path}/df_covid_preprocessed.csv')#.set_index('paper_id')\n",
    "\n",
    "# df_covid = df_covid.drop(\n",
    "#     [\"Unnamed: 0\", \"authors\", \"journal\"], axis=1)\n",
    "\n",
    "\n",
    "df_covid['body_text'] = df_covid['body_text'].astype(str)\n",
    "df_covid['abstract'] = df_covid['abstract'].astype(str)\n",
    "\n",
    "df_covid.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC35282</td>\n",
       "      <td>objective this retrospective chart review desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC59543</td>\n",
       "      <td>inflammatory diseases of the respiratory tract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC59549</td>\n",
       "      <td>surfactant proteind spd participates in the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC59574</td>\n",
       "      <td>endothelin1 et1 is a 21 amino acid peptide wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC59580</td>\n",
       "      <td>respiratory syncytial virus rsv and pneumonia ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                          paragraph\n",
       "0  PMC35282  objective this retrospective chart review desc...\n",
       "1  PMC59543  inflammatory diseases of the respiratory tract...\n",
       "2  PMC59549  surfactant proteind spd participates in the in...\n",
       "3  PMC59574  endothelin1 et1 is a 21 amino acid peptide wit...\n",
       "4  PMC59580  respiratory syncytial virus rsv and pneumonia ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "df_covid['body_text'] = df_covid['body_text'].apply(\n",
    "    lambda x: x.split('<br>'), meta=('abstract', 'str'))\n",
    "\n",
    "abstract_df = df_covid.drop(['body_text'], axis=1).replace('nan', np.nan).dropna(subset=['abstract'])\n",
    "df_sentences = abstract_df.rename(columns={'abstract': 'paragraph'})\n",
    "\n",
    "body_text_df = df_covid.drop(['abstract'], axis=1).rename(columns={'body_text': 'paragraph'})\n",
    "df_sentences = df_sentences.append(body_text_df.explode('paragraph'))\n",
    "\n",
    "# df_sentences = df_sentences.replace('NaN', np.nan).dropna(subset=['paragraph'])\n",
    "\n",
    "df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences.to_csv(f'{data_path}/covid_sentences.csv', single_file=True, compute=True, index=False)\n",
    "\n",
    "df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_dict = text.to_dict()\n",
    "# len_text = len(text_dict[\"paper_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paper_id_list = []\n",
    "# body_text_list = []\n",
    "\n",
    "# title_list = []\n",
    "# abstract_list = []\n",
    "# abstract_summary_list = []\n",
    "# for i in tqdm(range(0, len_text)):\n",
    "#     paper_id = text_dict[\"paper_id\"][i]\n",
    "#     body_text = text_dict[\"body_text\"][i].split(\"<br>\")\n",
    "#     title = text_dict[\"title\"][i]\n",
    "#     abstract = text_dict[\"abstract\"][i]\n",
    "#     abstract_summary = text_dict[\"abstract_summary\"][i]\n",
    "#     for b in body_text:\n",
    "#         paper_id_list.append(paper_id)\n",
    "#         body_text_list.append(b)\n",
    "#         title_list.append(title)\n",
    "#         abstract_list.append(abstract)\n",
    "#         abstract_summary_list.append(abstract_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sentences = pd.DataFrame({\"paper_id\": paper_id_list}, index=body_text_list)\n",
    "# df_sentences.to_csv(f'{root_path}/covid_sentences_body.csv')\n",
    "# df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask import dataframe as dd\n",
    "\n",
    "# df_sentences = pd.DataFrame({\"paper_id\": paper_id_list, \"title\": title_list,\n",
    "#                             \"abstract\": abstract_list, \"abstract_summary\": abstract_summary_list}, index=body_text_list)\n",
    "# df_sentences = dd.from_pandas(df_sentences)\n",
    "# df_sentences.to_csv(f'{root_path}/covid_sentences.csv')\n",
    "# df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PMC35282</td>\n",
       "      <td>objective this retrospective chart review desc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PMC59543</td>\n",
       "      <td>inflammatory diseases of the respiratory tract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PMC59549</td>\n",
       "      <td>surfactant proteind spd participates in the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PMC59574</td>\n",
       "      <td>endothelin1 et1 is a 21 amino acid peptide wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PMC59580</td>\n",
       "      <td>respiratory syncytial virus rsv and pneumonia ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   paper_id                                          paragraph\n",
       "0  PMC35282  objective this retrospective chart review desc...\n",
       "1  PMC59543  inflammatory diseases of the respiratory tract...\n",
       "2  PMC59549  surfactant proteind spd participates in the in...\n",
       "3  PMC59574  endothelin1 et1 is a 21 amino acid peptide wit...\n",
       "4  PMC59580  respiratory syncytial virus rsv and pneumonia ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "\n",
    "df_sentences = dd.read_csv(f'{data_path}/covid_sentences.csv', blocksize=32e6)#.set_index('paper_id')#.rename(columns={'Unnamed: 0': 'index'})\n",
    "\n",
    "df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sentences = df_sentences.set_index(\"Unnamed: 0\")\n",
    "\n",
    "# df_sentences.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_covid.to_csv(f'{root_path}/covid_sentences.csv', single_file=True, compute=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sentences = df_sentences[\"paper_id\"].to_dict()\n",
    "# df_sentences_list = list(df_sentences.keys())\n",
    "# len(df_sentences_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(df_sentences.keys())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sentences_list = [str(d) for d in tqdm(df_sentences_list)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py\n",
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# embedder = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "embedder = SentenceTransformer(f'{all_data_path}/models/pretrained/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder.save(f'{root_path}/models/pretrained/', 'multi-qa-MiniLM-L6-cos-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "class SentenceList(Sequence):\n",
    "    def __init__(self, csv_path):\n",
    "        # Read in the file once and build a list of line offsets\n",
    "        self.f_covid_sentences = open(csv_path)\n",
    "        self.header_line = \"\"\n",
    "        self.line_offset = []\n",
    "\n",
    "        self.init_offsets()\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def init_offsets(self):\n",
    "        self.header_line = self.f_covid_sentences.readline()\n",
    "\n",
    "        offset = len(self.header_line)\n",
    "        for line in self.f_covid_sentences:\n",
    "            self.line_offset.append(offset)\n",
    "            offset += len(line)\n",
    "\n",
    "        self.f_covid_sentences.seek(0)\n",
    "        \n",
    "        # print(self.line_offset)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.f_covid_sentences.seek(self.line_offset[i])\n",
    "        line = self.f_covid_sentences.readline()\n",
    "        # print(line)\n",
    "\n",
    "        return ' '.join(line.split(',')[1:])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offset)\n",
    "\n",
    "# Let's test it:\n",
    "sentence_list = SentenceList(f'{data_path}/covid_sentences.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objective this retrospective chart review describes the epidemiology and clinical features of 40 patients with cultureproven mycoplasma pneumoniae infections at king abdulaziz university hospital jeddah saudi arabia methods patients with positive m pneumoniae cultures from respiratory specimens from january 1997 through december 1998 were identified through the microbiology records charts of patients were reviewed results 40 patients were identified 33 825 of whom required admission most infections 925 were communityacquired the infection affected all age groups but was most common in infants 325 and preschool children 225 it occurred yearround but was most common in the fall 35 and spring 30 more than threequarters of patients 775 had comorbidities twentyfour isolates 60 were associated with pneumonia 14 35 with upper respiratory tract infections and 2 5 with bronchiolitis cough 825 fever 75 and malaise 588 were the most common symptoms and crepitations 60 and wheezes 40 were the most common signs most patients with pneumonia had crepitations 792 but only 25 had bronchial breathing immunocompromised patients were more likely than nonimmunocompromised patients to present with pneumonia 89 versus 1631 p  005 of the 24 patients with pneumonia 14 583 had uneventful recovery 4 167 recovered following some complications 3 125 died because of m pneumoniae infection and 3 125 died due to underlying comorbidities the 3 patients who died of m pneumoniae pneumonia had other comorbidities conclusion our results were similar to published data except for the finding that infections were more common in infants and preschool children and that the mortality rate of pneumonia in patients with comorbidities was high\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(sentence_list[0])\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 4306/4306 [13:52<00:00,  5.17it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Corpus with example sentences\n",
    "# corpus = df_sentences['paragraph']\n",
    "\n",
    "# corpus.compute()[1]\n",
    "\n",
    "if not os.path.exists(f'{data_path}/corpus_embeddings.npy'):\n",
    "    corpus_embeddings = embedder.encode(\n",
    "        sentence_list, device='cuda', show_progress_bar=True)\n",
    "\n",
    "    torch.save(corpus_embeddings, f'{data_path}/corpus_embeddings.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_csv(f'{root_path}/covid_sentences.csv', index_col=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOT SCALABLE\n",
    "# df_sentences = df_sentences.compute()\n",
    "\n",
    "# df_sentences.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import scipy.spatial\n",
    "import torch\n",
    "\n",
    "corpus_embeddings = torch.load(f'{data_path}/corpus_embeddings.npy')\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['What has been published about medical care?',\n",
    "           'Knowledge of the frequency, manifestations, and course of extrapulmonary manifestations of COVID-19, including, but not limited to, possible cardiomyopathy and cardiac arrest',\n",
    "           'Use of AI in real-time health care delivery to evaluate interventions, risk factors, and outcomes in a way that could not be done manually',\n",
    "           'Resources to support skilled nursing facilities and long term care facilities.',\n",
    "           'Mobilization of surge medical staff to address shortages in overwhelmed communities .',\n",
    "           'Age-adjusted mortality data for Acute Respiratory Distress Syndrome (ARDS) with/without other organ failure – particularly for viral etiologies .']\n",
    "query_embeddings = embedder.encode(queries, device='cuda', show_progress_bar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "\n",
      "\n",
      "=========================================================\n",
      "==========================Query==============================\n",
      "=== What has been published about medical care? =====\n",
      "=========================================================\n",
      "Score:    (Score: 0.6168) \n",
      "\n",
      "Article Index:    74263 \n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17913/1404806141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Score:   \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"(Score: %.4f)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Article Index:   \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Paragraph:   \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_corpus_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;31m# row_dict = df_sentences.loc[df_sentences.index ==\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#                             corpus.loc[idx]].to_dict()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_corpus_row(idx):\n",
    "    row = sentence_list[idx]\n",
    "\n",
    "    return row.split(',')\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "closest_n = 5\n",
    "print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist(\n",
    "        [query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n=========================================================\")\n",
    "    print(\"==========================Query==============================\")\n",
    "    print(\"===\", query, \"=====\")\n",
    "    print(\"=========================================================\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(\"Score:   \", \"(Score: %.4f)\" % (1-distance), \"\\n\")\n",
    "        print(\"Article Index:   \", idx, \"\\n\")\n",
    "        print(\"Paragraph:   \", sentence_list[idx][:150], \"\\n\")\n",
    "        # row_dict = df_sentences.loc[df_sentences.index ==\n",
    "        #                             corpus.loc[idx]].to_dict()\n",
    "        # print(\"paper_id:  \", row_dict[\"paper_id\"][corpus[idx]], \"\\n\")\n",
    "        # print(\"Title:  \", row_dict[\"title\"][corpus[idx]], \"\\n\")\n",
    "        # print(\"Abstract:  \", row_dict[\"abstract\"][corpus[idx]], \"\\n\")\n",
    "        # print(\"Abstract_Summary:  \",\n",
    "        #       row_dict[\"abstract_summary\"][corpus[idx]], \"\\n\")\n",
    "        print(\"-------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: make a custom file (seekable) containing a list of embedings and it's corresponding paper id\n",
    "if possible: make it a data structure where finding the knn is < n^2, possibilities are quad-trees \n",
    "if possible: make it cuda optimized\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2ea2f29b5b448882058d44cbab5bc411432e8b9448117a1eba11f607af628be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('39venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
