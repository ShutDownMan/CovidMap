{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "dataset_size = 'full'\n",
    "all_data_path = './../data/'\n",
    "data_path = f'./../data/{dataset_size}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "class PapersList(Sequence):\n",
    "    def __init__(self, csv_path):\n",
    "        # Read in the file once and build a list of line offsets\n",
    "        self.df_csv_file = open(csv_path, 'rb')\n",
    "        self.header_line = \"\"\n",
    "        self.line_offset = []\n",
    "\n",
    "        self.init_offsets()\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def init_offsets(self):\n",
    "        self.header_line = self.df_csv_file.readline().decode('utf-8')\n",
    "\n",
    "        offset = len(self.header_line)\n",
    "        for line in self.df_csv_file:\n",
    "            self.line_offset.append(offset)\n",
    "            offset += len(line)\n",
    "\n",
    "        # print(self.line_offset)\n",
    "    \n",
    "    def generate_row(self, line):\n",
    "        str_buffer = StringIO('\\n'.join([self.header_line, line]))\n",
    "        mini_df = pd.read_csv(str_buffer)\n",
    "        mini_df.astype(str)\n",
    "\n",
    "        return mini_df.iloc[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.df_csv_file.seek(self.line_offset[i])\n",
    "        line = self.df_csv_file.readline().decode('utf-8')\n",
    "        # print('offset:', self.line_offset[i])\n",
    "        # print('line len:', len(line))\n",
    "\n",
    "        row = self.generate_row(line)\n",
    "\n",
    "        return row\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's test it:\n",
    "papers_list = PapersList(f'{data_path}/df_covid.csv')\n",
    "print(papers_list[0])\n",
    "print(papers_list[1])\n",
    "print(papers_list[2])\n",
    "\n",
    "# papers_list[0]\n",
    "# papers_list[1]\n",
    "# papers_list[2]\n",
    "# papers_list[3]\n",
    "\n",
    "\n",
    "print(len(papers_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to -  PostgreSQL 13.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 11.1.0, 64-bit \n",
      "\n",
      "{'user': 'jedi', 'channel_binding': 'prefer', 'dbname': 'cord', 'port': '5432', 'tty': '', 'options': '', 'sslmode': 'prefer', 'sslcompression': '0', 'ssl_min_protocol_version': 'TLSv1.2', 'gssencmode': 'prefer', 'krbsrvname': 'postgres', 'target_session_attrs': 'any'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = None\n",
    "cur = None\n",
    "\n",
    "try:\n",
    "        # Connect to the database and begin a transaction\n",
    "    conn = psycopg2.connect(\n",
    "        f\"dbname={os.environ['DB_DATABASE_NAME']} user={os.environ['DB_USER']} password={os.environ['DB_PASSWORD']}\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Executing a SQL query\n",
    "    cur.execute(\"SELECT version();\")\n",
    "    # Fetch result\n",
    "    record = cur.fetchone()\n",
    "    print(\"You are connected to - \", record[0], \"\\n\")\n",
    "    \n",
    "    print(conn.get_dsn_parameters())\n",
    "\n",
    "except (Exception) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'papers_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2741/3534916230.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m ;\"\"\"\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpaper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpapers_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mpaper_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'papers_list' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "sql = \"\"\"INSERT INTO papers\n",
    "    (paper_id, title, abstract, body)\n",
    "VALUES\n",
    "    (%s, %s, %s, %s)\n",
    "ON CONFLICT ON CONSTRAINT papers_pkey DO UPDATE SET\n",
    "    title = %s,\n",
    "    abstract = %s,\n",
    "    body = %s\n",
    ";\"\"\"\n",
    "\n",
    "for paper in papers_list:\n",
    "    paper_id = str(paper['paper_id'])\n",
    "    title = str(paper['title'])\n",
    "    abstract = str(paper['abstract'])\n",
    "    body = str(paper['body_text'])\n",
    "\n",
    "    try:\n",
    "        cur.execute(sql, [paper_id, title, abstract, body, title, abstract, body])\n",
    "        conn.commit()\n",
    "    except (Exception) as error:\n",
    "        #print(paper)\n",
    "        print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_id                                              PMC35282\n",
      "paragraph    objective this retrospective chart review desc...\n",
      "Name: 0, dtype: object\n",
      "paper_id                                              PMC59543\n",
      "paragraph    inflammatory diseases of the respiratory tract...\n",
      "Name: 0, dtype: object\n",
      "paper_id                                              PMC59549\n",
      "paragraph    surfactant proteind spd participates in the in...\n",
      "Name: 0, dtype: object\n",
      "451362\n"
     ]
    }
   ],
   "source": [
    "paragraph_list = PapersList(f'{data_path}/covid_sentences.csv')\n",
    "print(paragraph_list[0])\n",
    "print(paragraph_list[1])\n",
    "print(paragraph_list[2])\n",
    "\n",
    "print(len(paragraph_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "\n",
    "psycopg2.extensions.register_adapter(np.float32, psycopg2._psycopg.AsIs)\n",
    "\n",
    "# embedder = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "embedder = SentenceTransformer(f'{all_data_path}/models/py-pretrained/')\n",
    "\n",
    "def get_embedding(text):\n",
    "    # print(text)\n",
    "    embedding = embedder.encode(text, device='cuda')\n",
    "\n",
    "    magnitude = np.linalg.norm(embedding)\n",
    "    normalized_embedding = embedding/magnitude\n",
    "\n",
    "    return (normalized_embedding.tolist(), magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.float64' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2741/4146007691.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparagraph_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper_paragraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mparagraph_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nan'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.float64' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "\n",
    "for paper_paragraph in paragraph_list:\n",
    "    paper_id = paper_paragraph['paper_id']\n",
    "    paragraph_text = str(paper_paragraph['paragraph'])\n",
    "\n",
    "    if paragraph_text == 'nan':\n",
    "        continue\n",
    "    \n",
    "    embedding, magnitude = get_embedding(paragraph_text)\n",
    "\n",
    "    sql = \"\"\"INSERT INTO paragraphs\n",
    "        (paper_id, paragraph, embedding, embedding_magnitude)\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "    ;\"\"\"\n",
    "\n",
    "    # print(paper_id)\n",
    "    # print(len(embedding))\n",
    "    # print(magnitude)\n",
    "\n",
    "    try:\n",
    "        cur.execute(sql, [paper_id, paragraph_text, embedding, magnitude])\n",
    "        conn.commit()\n",
    "    except (Exception) as error:\n",
    "        #print(paper)\n",
    "        print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.enterprisedb.com/postgres-tutorials/indexing-documents-full-text-search-postgresql\n",
    "\n",
    "# CREATE FUNCTION update_tsv() RETURNS trigger\n",
    "#     LANGUAGE 'plpgsql' VOLATILE NOT LEAKPROOF\n",
    "# AS $BODY$\n",
    "# begin\n",
    "#   new.tsv :=\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.title, '')), 'A') ||\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.abstract, '')), 'B');\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.body, '')), 'D');\n",
    "#  return new;\n",
    "# end\n",
    "# $BODY$;\n",
    "# CREATE TRIGGER update_tsv\n",
    "#        BEFORE INSERT OR UPDATE ON papers\n",
    "#        FOR EACH ROW EXECUTE PROCEDURE update_tsv();\n",
    "\n",
    "# ( 'pregnant'::tsquery || to_tsquery('pregnancy') && ( to_tsquery('covid') || to_tsquery('Sars-Cov-2') ) && ( to_tsquery('trials') || to_tsquery('tests') || to_tsquery('experiment') ) )\n",
    "\n",
    "# SELECT\n",
    "#     ts_rank(\"tsv\", to_tsquery('pregnant | covid | trials')) AS \"rank\",\n",
    "#     paper_id,\n",
    "#     title\n",
    "# FROM\n",
    "#     papers\n",
    "# WHERE\n",
    "#     tsv @@ to_tsquery('pregnant | covid | trials')\n",
    "# ORDER BY rank DESC LIMIT 20\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2ea2f29b5b448882058d44cbab5bc411432e8b9448117a1eba11f607af628be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('39venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
