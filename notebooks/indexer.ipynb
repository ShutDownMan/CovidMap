{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "dataset_size = 'small'\n",
    "all_data_path = './../data/'\n",
    "data_path = f'./../data/{dataset_size}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "class PapersList(Sequence):\n",
    "    def __init__(self, csv_path):\n",
    "        # Read in the file once and build a list of line offsets\n",
    "        self.df_csv_file = open(csv_path, 'rb')\n",
    "        self.header_line = \"\"\n",
    "        self.line_offset = []\n",
    "\n",
    "        self.init_offsets()\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def init_offsets(self):\n",
    "        self.header_line = self.df_csv_file.readline().decode('utf-8')\n",
    "\n",
    "        offset = len(self.header_line)\n",
    "        for line in self.df_csv_file:\n",
    "            self.line_offset.append(offset)\n",
    "            offset += len(line)\n",
    "\n",
    "        # print(self.line_offset)\n",
    "    \n",
    "    def generate_row(self, line):\n",
    "        str_buffer = StringIO('\\n'.join([self.header_line, line]))\n",
    "        mini_df = pd.read_csv(str_buffer)\n",
    "        mini_df.astype(str)\n",
    "\n",
    "        return mini_df.iloc[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.df_csv_file.seek(self.line_offset[i])\n",
    "        line = self.df_csv_file.readline().decode('utf-8')\n",
    "        # print('offset:', self.line_offset[i])\n",
    "        # print('line len:', len(line))\n",
    "\n",
    "        row = self.generate_row(line)\n",
    "\n",
    "        return row\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_id                                            PMC7286226\n",
      "title        The absence of coronavirus in expressed prosta...\n",
      "abstract     due to the cellular entry of the novel coronav...\n",
      "body_text    currently, the novel coronavirus disease (covi...\n",
      "Name: 0, dtype: object\n",
      "paper_id                                            PMC7239191\n",
      "title        SARS-CoV-2 receptor ACE2 expression in the hum...\n",
      "abstract                                                   NaN\n",
      "body_text     this editorial refers to â€˜cell type-specific ...\n",
      "Name: 0, dtype: object\n",
      "paper_id                                            PMC4653074\n",
      "title        PARP9-DTX3L ubiquitin ligase targets host hist...\n",
      "abstract     enhancing the response to interferon could off...\n",
      "body_text    the interferon signaling pathway is considered...\n",
      "Name: 0, dtype: object\n",
      "12500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Let's test it:\n",
    "papers_list = PapersList(f'{data_path}/df_covid_preprocessed.csv')\n",
    "print(papers_list[0])\n",
    "print(papers_list[1])\n",
    "print(papers_list[2])\n",
    "\n",
    "# papers_list[0]\n",
    "# papers_list[1]\n",
    "# papers_list[2]\n",
    "# papers_list[3]\n",
    "\n",
    "\n",
    "print(len(papers_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are connected to -  PostgreSQL 13.4 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 11.1.0, 64-bit \n",
      "\n",
      "{'user': 'jedi', 'channel_binding': 'prefer', 'dbname': 'cord', 'port': '5432', 'tty': '', 'options': '', 'sslmode': 'prefer', 'sslcompression': '0', 'ssl_min_protocol_version': 'TLSv1.2', 'gssencmode': 'prefer', 'krbsrvname': 'postgres', 'target_session_attrs': 'any'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conn = None\n",
    "cur = None\n",
    "\n",
    "try:\n",
    "        # Connect to the database and begin a transaction\n",
    "    conn = psycopg2.connect(\n",
    "        f\"dbname={os.environ['DB_DATABASE_NAME']} user={os.environ['DB_USER']} password={os.environ['DB_PASSWORD']}\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Executing a SQL query\n",
    "    cur.execute(\"SELECT version();\")\n",
    "    # Fetch result\n",
    "    record = cur.fetchone()\n",
    "    print(\"You are connected to - \", record[0], \"\\n\")\n",
    "    \n",
    "    print(conn.get_dsn_parameters())\n",
    "\n",
    "except (Exception) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "import numpy as np\n",
    "\n",
    "psycopg2.extensions.register_adapter(np.float32, psycopg2._psycopg.AsIs)\n",
    "\n",
    "# embedder = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "embedder = SentenceTransformer(f'{all_data_path}/models/py2-pretrained/')\n",
    "\n",
    "def get_embedding(text):\n",
    "    # print(text)\n",
    "    embedding = embedder.encode(text, device='cuda')\n",
    "    \n",
    "    return embedding.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql = \"\"\"INSERT INTO papers\n",
    "    (paper_id, title, abstract, body, abstract_embedding, body_embedding)\n",
    "VALUES\n",
    "    (%s, %s, %s, %s, %s, %s)\n",
    "ON CONFLICT ON CONSTRAINT papers_pkey DO UPDATE SET\n",
    "    title = %s,\n",
    "    abstract = %s,\n",
    "    body = %s,\n",
    "    abstract_embedding = %s,\n",
    "    body_embedding = %s\n",
    ";\"\"\"\n",
    "\n",
    "for paper in papers_list:\n",
    "    paper_id = str(paper['paper_id'])\n",
    "    title = str(paper['title'])\n",
    "    abstract = str(paper['abstract'])\n",
    "    body = str(paper['body_text'])\n",
    "    abstract_embedding = get_embedding(abstract)\n",
    "    # body_embedding = get_embedding(body)\n",
    "    body_embedding = abstract_embedding\n",
    "\n",
    "    try:\n",
    "        cur.execute(sql, [\n",
    "            paper_id, title, abstract, body, abstract_embedding, body_embedding,\n",
    "            title, abstract, body, abstract_embedding, body_embedding\n",
    "        ])\n",
    "        conn.commit()\n",
    "    except (Exception) as error:\n",
    "        #print(paper)\n",
    "        print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper_id                                            PMC7286226\n",
      "paragraph    due to the cellular entry of the novel coronav...\n",
      "Name: 0, dtype: object\n",
      "paper_id                                            PMC4653074\n",
      "paragraph    enhancing the response to interferon could off...\n",
      "Name: 0, dtype: object\n",
      "paper_id                                            PMC7527265\n",
      "paragraph    background: european member states, the europe...\n",
      "Name: 0, dtype: object\n",
      "357000\n"
     ]
    }
   ],
   "source": [
    "paragraph_list = PapersList(f'{data_path}/covid_sentences.csv')\n",
    "print(paragraph_list[0])\n",
    "print(paragraph_list[1])\n",
    "print(paragraph_list[2])\n",
    "\n",
    "print(len(paragraph_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder.save(f'{all_data_path}/models/py-pretrained/', 'distiluse-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql = \"\"\"INSERT INTO paragraphs\n",
    "    (paper_id, content, embedding)\n",
    "VALUES (%s, %s, %s)\n",
    ";\"\"\"\n",
    "\n",
    "for paper_paragraph in paragraph_list:\n",
    "    paper_id = paper_paragraph['paper_id']\n",
    "    paragraph_text = str(paper_paragraph['paragraph'])\n",
    "\n",
    "    if paragraph_text == 'nan':\n",
    "        continue\n",
    "\n",
    "    embedding = get_embedding(paragraph_text)\n",
    "\n",
    "    try:\n",
    "        cur.execute(sql, [paper_id, paragraph_text, embedding])\n",
    "        conn.commit()\n",
    "    except (Exception) as error:\n",
    "        #print(paper)\n",
    "        print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_query = \"the quick brown fox jumped over the lazy dog\"\n",
    "\n",
    "# get_embedding(test_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.enterprisedb.com/postgres-tutorials/indexing-documents-full-text-search-postgresql\n",
    "\n",
    "# CREATE FUNCTION update_tsv() RETURNS trigger\n",
    "#     LANGUAGE 'plpgsql' VOLATILE NOT LEAKPROOF\n",
    "# AS $BODY$\n",
    "# begin\n",
    "#   new.tsv :=\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.title, '')), 'A') ||\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.abstract, '')), 'B');\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.body, '')), 'D');\n",
    "#  return new;\n",
    "# end\n",
    "# $BODY$;\n",
    "# CREATE TRIGGER update_tsv\n",
    "#        BEFORE INSERT OR UPDATE ON papers\n",
    "#        FOR EACH ROW EXECUTE PROCEDURE update_tsv();\n",
    "\n",
    "# ( 'pregnant'::tsquery || to_tsquery('pregnancy') && ( to_tsquery('covid') || to_tsquery('Sars-Cov-2') ) && ( to_tsquery('trials') || to_tsquery('tests') || to_tsquery('experiment') ) )\n",
    "\n",
    "# SELECT\n",
    "#     ts_rank(\"tsv\", to_tsquery('pregnant | covid | trials')) AS \"rank\",\n",
    "#     paper_id,\n",
    "#     title\n",
    "# FROM\n",
    "#     papers\n",
    "# WHERE\n",
    "#     tsv @@ to_tsquery('pregnant | covid | trials')\n",
    "# ORDER BY rank DESC LIMIT 20\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2ea2f29b5b448882058d44cbab5bc411432e8b9448117a1eba11f607af628be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('39venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
