{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "dataset_size = 'small'\n",
    "all_data_path = './../data/'\n",
    "data_path = f'./../data/{dataset_size}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "class PapersList(Sequence):\n",
    "    def __init__(self, csv_path):\n",
    "        # Read in the file once and build a list of line offsets\n",
    "        self.df_csv_file = open(csv_path, 'rb')\n",
    "        self.header_line = \"\"\n",
    "        self.line_offset = []\n",
    "\n",
    "        self.init_offsets()\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def init_offsets(self):\n",
    "        self.header_line = self.df_csv_file.readline().decode('utf-8')\n",
    "\n",
    "        offset = len(self.header_line)\n",
    "        for line in self.df_csv_file:\n",
    "            self.line_offset.append(offset)\n",
    "            offset += len(line)\n",
    "\n",
    "        # print(self.line_offset)\n",
    "    \n",
    "    def generate_row(self, line):\n",
    "        str_buffer = StringIO('\\n'.join([self.header_line, line]))\n",
    "        mini_df = pd.read_csv(str_buffer)\n",
    "        mini_df.astype(str)\n",
    "\n",
    "        return mini_df.iloc[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        self.df_csv_file.seek(self.line_offset[i])\n",
    "        line = self.df_csv_file.readline().decode('utf-8')\n",
    "        # print('offset:', self.line_offset[i])\n",
    "        # print('line len:', len(line))\n",
    "\n",
    "        row = self.generate_row(line)\n",
    "\n",
    "        return row\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.line_offset)\n",
    "\n",
    "# Let's test it:\n",
    "papers_list = PapersList(f'{data_path}/df_covid.csv')\n",
    "print(papers_list[0])\n",
    "print(papers_list[1])\n",
    "print(papers_list[2])\n",
    "\n",
    "# papers_list[0]\n",
    "# papers_list[1]\n",
    "# papers_list[2]\n",
    "# papers_list[3]\n",
    "\n",
    "\n",
    "print(len(papers_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "conn = None\n",
    "cur = None\n",
    "\n",
    "try:\n",
    "        # Connect to the database and begin a transaction\n",
    "    conn = psycopg2.connect(\n",
    "        f\"dbname={os.environ['DB_DATABASE_NAME']} user={os.environ['DB_USER']} password={os.environ['DB_PASSWORD']}\")\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Executing a SQL query\n",
    "    cur.execute(\"SELECT version();\")\n",
    "    # Fetch result\n",
    "    record = cur.fetchone()\n",
    "    print(\"You are connected to - \", record[0], \"\\n\")\n",
    "    \n",
    "    print(conn.get_dsn_parameters())\n",
    "\n",
    "except (Exception) as error:\n",
    "    print(\"Error while connecting to PostgreSQL\", error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for paper in papers_list:\n",
    "    paper_id = str(paper['paper_id'])\n",
    "    title = str(paper['title'])\n",
    "    abstract = str(paper['abstract'])\n",
    "    body = str(paper['body_text'])\n",
    "\n",
    "    sql = \"\"\"INSERT INTO papers\n",
    "        (paper_id, title, abstract, body)\n",
    "    VALUES\n",
    "        (%s, %s, %s, %s)\n",
    "    ON CONFLICT ON CONSTRAINT papers_pkey DO UPDATE SET\n",
    "        title = %s,\n",
    "        abstract = %s,\n",
    "        body = %s\n",
    "    ;\"\"\"\n",
    "\n",
    "    try:\n",
    "        cur.execute(sql, [paper_id, title, abstract, body, title, abstract, body])\n",
    "        conn.commit()\n",
    "    except (Exception) as error:\n",
    "        #print(paper)\n",
    "        print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_list = PapersList(f'{data_path}/covid_sentences.csv')\n",
    "print(paragraph_list[0])\n",
    "print(paragraph_list[1])\n",
    "print(paragraph_list[2])\n",
    "\n",
    "print(len(paragraph_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/UKPLab/sentence-transformers/blob/master/examples/application_semantic_search.py\n",
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "\n",
    "psycopg2.extensions.register_adapter(np.float32, psycopg2._psycopg.AsIs)\n",
    "\n",
    "# embedder = SentenceTransformer('distiluse-base-multilingual-cased')\n",
    "embedder = SentenceTransformer(f'{all_data_path}/models/py-pretrained/')\n",
    "\n",
    "def get_embedding(text):\n",
    "    embedding = embedder.encode(text, device='cuda')\n",
    "\n",
    "    magnitude = np.linalg.norm(embedding)\n",
    "    normalized_embedding = embedding/magnitude\n",
    "\n",
    "    return (normalized_embedding.tolist(), magnitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for paper_paragraph in paragraph_list:\n",
    "    paper_id = paper_paragraph['paper_id']\n",
    "    paragraph_text = paper_paragraph['paragraph']\n",
    "    \n",
    "    embedding, magnitude = get_embedding(paragraph_text)\n",
    "\n",
    "    sql = \"\"\"INSERT INTO paragraphs\n",
    "        (paper_id, paragraph, embedding, embedding_magnitude)\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "    ;\"\"\"\n",
    "\n",
    "    # print(paper_id)\n",
    "    # print(len(embedding))\n",
    "    # print(magnitude)\n",
    "\n",
    "    try:\n",
    "        cur.execute(sql, [paper_id, paragraph_text, embedding, magnitude])\n",
    "        conn.commit()\n",
    "    except (Exception) as error:\n",
    "        #print(paper)\n",
    "        print(\"Error while connecting to PostgreSQL\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.enterprisedb.com/postgres-tutorials/indexing-documents-full-text-search-postgresql\n",
    "\n",
    "# CREATE FUNCTION update_tsv() RETURNS trigger\n",
    "#     LANGUAGE 'plpgsql' VOLATILE NOT LEAKPROOF\n",
    "# AS $BODY$\n",
    "# begin\n",
    "#   new.tsv :=\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.title, '')), 'A') ||\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.abstract, '')), 'B');\n",
    "#     setweight(to_tsvector('pg_catalog.english',\n",
    "#       coalesce(new.body, '')), 'D');\n",
    "#  return new;\n",
    "# end\n",
    "# $BODY$;\n",
    "# CREATE TRIGGER update_tsv\n",
    "#        BEFORE INSERT OR UPDATE ON papers\n",
    "#        FOR EACH ROW EXECUTE PROCEDURE update_tsv();\n",
    "\n",
    "# ( 'pregnant'::tsquery || to_tsquery('pregnancy') && ( to_tsquery('covid') || to_tsquery('Sars-Cov-2') ) && ( to_tsquery('trials') || to_tsquery('tests') || to_tsquery('experiment') ) )\n",
    "\n",
    "# SELECT\n",
    "#     ts_rank(\"tsv\", to_tsquery('pregnant | covid | trials')) AS \"rank\",\n",
    "#     paper_id,\n",
    "#     title\n",
    "# FROM\n",
    "#     papers\n",
    "# WHERE\n",
    "#     tsv @@ to_tsquery('pregnant | covid | trials')\n",
    "# ORDER BY rank DESC LIMIT 20\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a2ea2f29b5b448882058d44cbab5bc411432e8b9448117a1eba11f607af628be"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('39venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
